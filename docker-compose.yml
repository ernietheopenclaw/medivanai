version: '3.8'

services:
  medivanai-api:
    build:
      context: .
      dockerfile: backend/Dockerfile
    ports:
      - "8000:8000"
    environment:
      - MOCK_MODE=${MOCK_MODE:-false}
      - NIM_ENDPOINT=http://nim-llm:8000/v1
    volumes:
      - /tmp/medivanai_uploads:/tmp/medivanai_uploads
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
    depends_on:
      - nim-llm

  nim-llm:
    image: nvcr.io/nim/meta/llama-3.1-8b-instruct:latest
    ports:
      - "8080:8000"
    environment:
      - NGC_API_KEY=${NGC_API_KEY}
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
