# ğŸ¥ MediVan â€” Mobile Diagnostic Hub

**Offline multi-modal medical diagnostic screening for underserved communities.**

MediVan AI turns a Dell Pro Max GB10 into a portable AI-powered screening station. A clinician in a mobile health van connects their phone via Tailscale and captures medical images. On-device AI models identify the image type, classify findings, and generate a holistic patient report â€” all without internet access.

> ğŸ† Built for the Dell Pro Max GB10 Hackathon at NYU Center for Data Science

---

## ğŸ¯ Why MediVan AI?

- **60M+ Americans** live in medically underserved areas
- Mobile health vans bridge the gap â€” but lack diagnostic AI
- MediVan AI brings specialist-level screening to the point of care
- **Zero cloud dependency** â€” all inference runs on the GB10
- **HIPAA-aligned** â€” patient images never leave the device

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“± Phone Browser (PWA via Tailscale)               â”‚
â”‚  Camera capture / Image upload                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                   â”‚ HTTPS (Tailscale)
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ–¥ï¸ Dell Pro Max GB10                               â”‚
â”‚                                                     â”‚
â”‚  FastAPI Server (:8000)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ 1. CLIP/SigLIP Image Router (zero-shot)     â”‚    â”‚
â”‚  â”‚    "skin lesion" vs "chest xray" vs "fundus" â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚             â–¼          â–¼          â–¼                  â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”         â”‚
â”‚  â”‚ ğŸ”¬ Skin ViT â”‚ â”‚ ğŸ« CXR   â”‚ â”‚ ğŸ‘ï¸ DR    â”‚         â”‚
â”‚  â”‚ HAM10000    â”‚ â”‚ ViT      â”‚ â”‚ ViT      â”‚         â”‚
â”‚  â”‚ 7 classes   â”‚ â”‚ 7 classesâ”‚ â”‚ 5 grades â”‚         â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”˜         â”‚
â”‚         â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€-â”˜               â”‚
â”‚                        â–¼                            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ ğŸ“š RAG: Clinical Guidelines (FAISS local)   â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â”‚                     â–¼                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”‚
â”‚  â”‚ ğŸ§  LLM (NIM): Holistic Patient Report       â”‚    â”‚
â”‚  â”‚    Llama 3.1 8B via NVIDIA NIM              â”‚    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ”§ NVIDIA Software Stack

| Component | Technology |
|-----------|-----------|
| Image Router | OpenCLIP (ViT-B/32) â€” zero-shot classification |
| Skin Classifier | ViT-Large/32-384 fine-tuned on HAM10000 |
| Chest X-ray | ViT fine-tuned on chest X-ray datasets |
| Eye/DR | ViT fine-tuned on diabetic retinopathy |
| Clinical LLM | Llama 3.1 8B via **NVIDIA NIM** |
| RAG Embeddings | Sentence-Transformers (all-MiniLM-L6-v2) |
| Vector Search | FAISS (CPU) |
| GPU Runtime | NVIDIA Container Toolkit / PyTorch |

---

## ğŸ’¾ Memory Budget (GB10 â€” 128GB unified RAM)

| Model | ~VRAM | Notes |
|-------|-------|-------|
| CLIP ViT-B/32 | ~0.6 GB | Image routing |
| Skin ViT-L/32 | ~1.2 GB | HAM10000 classifier |
| Chest ViT | ~0.3 GB | X-ray classifier |
| DR ViT | ~0.3 GB | Retinopathy grading |
| Llama 3.1 8B (NIM) | ~16 GB | Report generation |
| FAISS + Embeddings | ~0.5 GB | RAG retrieval |
| **Total** | **~19 GB** | Well within 128GB budget |

---

## ğŸš€ Quick Start

### Prerequisites
- Dell Pro Max GB10 (ARM64) or any Linux/macOS/Windows with Python 3.10+
- NVIDIA GPU (optional â€” works in mock mode without GPU)
- Node.js 18+ (for frontend build)

### 1. Clone & Install

```bash
git clone https://github.com/ernietheopenclaw/medivanai.git
cd medivanai

# Backend
pip install -r backend/requirements.txt

# Frontend
cd frontend && npm install && npm run build && cd ..
```

### 2. Run (Mock Mode â€” no GPU needed)

```bash
MOCK_MODE=true python -m uvicorn backend.main:app --host 0.0.0.0 --port 8000
```

### 3. Run (Full â€” with models)

```bash
MOCK_MODE=false python -m uvicorn backend.main:app --host 0.0.0.0 --port 8000
```

### 4. Docker (GB10 deployment)

```bash
docker compose up --build
```

---

## ğŸ“± Phone Access via Tailscale

1. Install Tailscale on the GB10: `bash scripts/setup-tailscale.sh`
2. Install Tailscale on your phone (iOS/Android)
3. Join the same Tailnet (same account)
4. Open `http://<gb10-tailscale-ip>:8000` in Chrome
5. Add to Home Screen for PWA experience

Tailscale provides:
- **Secure P2P connection** â€” no public internet needed
- **Valid HTTPS certs** â€” enables camera access on phone
- **Zero config networking** â€” works anywhere

---

## ğŸ“‹ Demo Flow

1. **Open MediVan AI** on phone browser
2. **Start Session** â€” creates a new patient screening
3. **Capture/Upload** a skin lesion photo â†’ AI classifies (e.g., "melanocytic nevi, 87% confidence, Low Risk")
4. **Capture/Upload** a chest X-ray â†’ AI classifies (e.g., "pneumonia, 82% confidence, High Risk")
5. **Capture/Upload** a fundus photo â†’ AI grades DR (e.g., "Moderate NPDR, 78% confidence")
6. **Generate Report** â€” LLM synthesizes all findings into a holistic patient report with cross-modality insights and priority referrals

---

## ğŸ”’ Privacy & HIPAA

- **All inference runs on-device** â€” no cloud API calls
- **Patient images stored in volatile memory** â€” cleared on restart
- **No telemetry or logging of PHI**
- **Tailscale connection** â€” encrypted P2P, no data traverses public internet
- **Session data** â€” in-memory only, not persisted to disk

---

## ğŸ“ Project Structure

```
medivanai/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py              # FastAPI application
â”‚   â”œâ”€â”€ config.py             # Configuration
â”‚   â”œâ”€â”€ services/
â”‚   â”‚   â”œâ”€â”€ router.py         # CLIP image router
â”‚   â”‚   â”œâ”€â”€ skin_classifier.py
â”‚   â”‚   â”œâ”€â”€ chest_classifier.py
â”‚   â”‚   â”œâ”€â”€ eye_classifier.py
â”‚   â”‚   â”œâ”€â”€ report_generator.py  # NIM LLM integration
â”‚   â”‚   â”œâ”€â”€ rag.py            # FAISS + guidelines
â”‚   â”‚   â””â”€â”€ session_manager.py
â”‚   â”œâ”€â”€ knowledge/            # Clinical guidelines (MD)
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ Dockerfile
â”œâ”€â”€ frontend/                 # Next.js PWA
â”‚   â”œâ”€â”€ src/app/              # Pages
â”‚   â””â”€â”€ src/components/       # UI components
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ setup-tailscale.sh
â”‚   â””â”€â”€ start.sh
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ README.md
```

---

## âš ï¸ Disclaimer

MediVan AI is an **AI-assisted screening tool** for research and demonstration purposes. It does **NOT** constitute medical diagnosis. All findings must be confirmed by a qualified healthcare provider. Clinical decisions should be based on comprehensive evaluation, not AI screening alone.

---

## ğŸ“„ License

MIT â€” see [LICENSE](LICENSE)

